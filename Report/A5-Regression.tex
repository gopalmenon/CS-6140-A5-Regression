\documentclass[11pt]{article}

\usepackage{classDM17}
\usepackage{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\title{Asmt 5: Regression}
\author{Gopal Menon\\Turn in through Canvas by 2:45pm: \\
Wednesday, April 12}
\date{}

\begin{document}
\maketitle


%
\section{Singular Value Decomposition (20 points)}
First we will compute the SVD of the matrix $A$ we have loaded
$$
[U,S,V] = svd(A)
$$
Then take the top $k$ components of $A$ for values of $k = 1$ through $k=10$ using

\begin{equation*}
\begin{aligned}
Uk &= U(:,1:k)\\
Sk &= S(1:k,1:k)\\
Vk &= V(:,1:k)\\
Ak &= Uk*Sk*Vk'\\
\end{aligned}
\end{equation*}

\paragraph{A: (10 points):} 
Compute and report the $L_2$ norm of the difference between $A$ and $Ak$ for each value of $k$ using
$$
norm(A-Ak,2)
$$

    \begin{table}[!h] 
    \centering
    \caption{$L_2$ norm of $A-Ak$ for each value of $k$}
    \label{AAkL2}
    \begin{tabular}{|c|c|}
      \hline
   $k$  & $L_2$ Norm  \\
      \hline      
      $1$ &      $40.483$  \\
      \hline
      $2$ &      $26.717$  \\
      \hline
      $3$ &      $25.000$  \\
      \hline
      $4$ &      $22.192$  \\
      \hline
      $5$ &      $17.675$  \\
      \hline
      $6$ &      $15.813$  \\
      \hline
      $7$ &      $13.351$  \\
      \hline
      $8$ &      $12.188$  \\
      \hline
      $9$ &      $9.1206$  \\
      \hline
      $10$ &      $9.0000$  \\
      \hline
    \end{tabular}
\end{table}

\paragraph{B (5 points):}
Find the smallest value $k$ so that the $L_2$ norm of $A-Ak$ is less than $10\%$ that of $A$; $k$ might or might not be larger than $10$.\\

The $L_2$ norm of $A$ is $120.19$ and $10\%$ of that is $12.019$. From table \ref{AAkL2}, we can see that the smallest value of $k$ such that the $L_2$ norm of $A-Ak$ is less than $10\%$ that of $A$ is $9$.

\paragraph{C (5 points):}

Treat the matrix as $1125$ points in $30$ dimensions. Plot the points in $2$ dimensions in the way that minimizes the sum of residuals squared.\\

The first two right singular vectors were used and all $1125$ points in $30$ dimensions were projected on them to get $1125$ points in $2$ dimensions. Since the first two singular vectors represent eigen vectors, this projection will result in the least sum of residuals squared. The plot is shown below in figure \ref{MinRes}.

\begin{figure}[!htb]
\centering
\includegraphics[width=5in]{figures/MinRes.png}
\caption{Points plotted in 2D to minimize sum of residuals squared}
\label{MinRes}
\end{figure} 

\section{Frequent Directions and Random Projections (40 points)}

\paragraph{A (20 points):}

\begin{itemize}
\item How large does $l$ need to be for the above error to be at most $\frac{\norm{A}_F^2}{10}$?\\
$$
\frac{\norm{A}_F^2}{10} = 1903.7
$$

\begin{table}[!h] 
    \centering
    \caption{Error for values of $l$}
    \label{ErrL}
    \begin{tabular}{|c|c|}
      \hline
   $l$  & Error  \\
      \hline      
      $3$ &      $2289.9$  \\
      \hline
      $4$ &      $1427.9$  \\
      \hline
      $5$ &      $965.01$  \\
      \hline
      $6$ &      $703.24$  \\
      \hline
      $7$ &      $494.53$  \\
      \hline
      $8$ &      $350.53$  \\
      \hline
      $9$ &      $247.37$  \\
      \hline
      $10$ &      $176.91$  \\
      \hline
    \end{tabular}
\end{table}

From table \ref{ErrL} we can see that with $l=4$, the error is at most $\frac{\norm{A}_F^2}{10}$.

\item How does this compare to the theoretical bound (e.g. for $k = 0$).

The theoretical bound is given by $\frac{\norm{A-A_k}_F^2}{l-k}$. When $k=0$, the bound becomes $\frac{\norm{A}_F^2}{l}$. This bound evaluates to $4759.3$ when $l=4$.

\item How large does $l$ need to be for the above error to be at most $\frac{\norm{A-A_k}_F^2}{10}$ for $k = 2$?

For $k = 2$, $\frac{\norm{A-A_k}_F^2}{10} = 295.18$. From table \ref{ErrL}, we can see that when $l=9$, the error is at most $\frac{\norm{A-A_k}_F^2}{10}$ for $k = 2$.

\end{itemize}
\end{document}
